{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "%cd /home/schirrmr/\n",
    "# switch to cpu\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png' \n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 3.0)\n",
    "from hyperoptim.results import load_data_frame, remove_columns_with_same_value, dataset_averaged_frame\n",
    "from hyperoptim.results import mean_identical_exps\n",
    "import pandas as pd\n",
    "from hyperoptim.results import remove_columns_with_same_value, remove_indices_with_same_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.morestats import wilcoxon\n",
    "import random\n",
    "\n",
    "def to_numeric_where_possible(df):\n",
    "    df = df.copy(deep=True)\n",
    "    for col in df.columns:\n",
    "        df.loc[:,col] = pd.to_numeric(df.loc[:,col], errors='ignore')\n",
    "    return df\n",
    "\n",
    "def round_numeric_columns(df, decimals):\n",
    "    df = df.copy(deep=True)\n",
    "    tmp = df.select_dtypes(include=[np.number], exclude=[np.timedelta64])\n",
    "    df.loc[:, tmp.columns] = np.round(tmp, decimals)\n",
    "    return df\n",
    "\n",
    "def perm_mean_diffs_sampled(a, b, n_diffs=None):\n",
    "    \"\"\"Compute differences between all permutations of  labels.\n",
    "    Version that samples.\n",
    "    Parameters\n",
    "    --------------\n",
    "    a: list or numpy array\n",
    "    b: list or numpy array\n",
    "    n_diffs: int\n",
    "        How many diffs/samples to compute.\n",
    "    Returns\n",
    "    -------\n",
    "    all_diffs: 1d-array of float\n",
    "        Sampled mean differences.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_exps = len(a)\n",
    "    all_bit_masks = [2 ** n for n in range(n_exps-1,-1,-1)]\n",
    "    if n_diffs is None:\n",
    "        n_diffs = 2**n_exps\n",
    "        i_all_masks = range(n_diffs)\n",
    "    else:\n",
    "        random.seed(39483948)\n",
    "        # take samples of all masks, always add identity mask\n",
    "        i_all_masks = random.sample(range(0,2**n_exps-1), n_diffs - 1)\n",
    "        i_all_masks = i_all_masks + [(2**n_exps)-1]\n",
    "        # verification this is actually identity mask for code below:\n",
    "        test_i_mask = i_all_masks[-1]\n",
    "        test_mask = (np.bitwise_and(test_i_mask, all_bit_masks) > 0) * 2 - 1\n",
    "        assert np.array_equal(a - b, (test_mask * a)  -test_mask * b)\n",
    "\n",
    "        \n",
    "    all_diffs = np.float32(np.ones(n_diffs) * np.nan)\n",
    "    for i_diff, i_mask in enumerate(i_all_masks):\n",
    "        # masks has -1s and 1s,\n",
    "        # 1 interpretable as\n",
    "        # correct value selected\n",
    "        # -1 as randomly flipped value/\"incorrect\" value selected\n",
    "        # *2 makes values between 2 and 0, then -1 to make \n",
    "        # values between 1 and -1\n",
    "        mask = (np.bitwise_and(i_mask, all_bit_masks) > 0) * 2 - 1\n",
    "        # mean later by dividing by n_exp\n",
    "        # seems to be a little bit faster that way\n",
    "        diff = np.sum((mask * a)  -mask * b)\n",
    "        all_diffs[i_diff] = diff\n",
    "    all_diffs = all_diffs / float(n_exps)\n",
    "    return all_diffs\n",
    "\n",
    "def perm_mean_diffs(a,b):\n",
    "    \"\"\"Compute differences between all permutations of  labels.\n",
    "    Assumes a and b are paired values,\n",
    "    a are values with label 0 and b with label 1.\n",
    "    Computes mean differences for all possible   \n",
    "    switches of 0 and 1 (but keeping pairs together, i.e.\n",
    "    2 ^ len(a) switches).\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    a: list or numpy array\n",
    "    b: list or numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    diffs: 1d-numpy array\n",
    "        Differences between means of labelled values\n",
    "        for all label-switched values.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    http://www.stat.ncsu.edu/people/lu/courses/ST505/Ch4.pdf#page=10\n",
    "    http://stats.stackexchange.com/a/64215/56289\n",
    "    http://www.jarrodmillman.com/publications/millman2015thesis.pdf ->\n",
    "    https://github.com/statlab/permute python package \n",
    "    (probably, didnt read: http://finzi.psych.upenn.edu/R/library/EnvStats/html/twoSamplePermutationTestLocation.html)\n",
    "    \"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    assert len(a) == len(b)\n",
    "    n_exps = len(a)\n",
    "    all_masks = _create_masks(n_exps)\n",
    "    diffs = _compute_diffs(a, b, all_masks)\n",
    "    return diffs\n",
    "\n",
    "def perm_mean_diff_test(a,b, n_diffs=None):\n",
    "    \"\"\"Return two sided p-value of perm mean diff.\"\"\"\n",
    "    if n_diffs is None:\n",
    "        diffs = perm_mean_diffs(a, b)\n",
    "    else:\n",
    "        diffs = perm_mean_diffs_sampled(a, b, n_diffs)\n",
    "    \n",
    "    actual_diff = np.mean(a - b)\n",
    "    n_samples_as_large_diff = np.sum(np.abs(diffs) >= np.abs(actual_diff))\n",
    "    #if n_diffs is not None:\n",
    "    #    p_val = n_samples_as_large_diff + 1 /\n",
    "    return n_samples_as_large_diff / float(len(diffs))\n",
    "\n",
    "\n",
    "def _create_masks(n_exps):\n",
    "    \"\"\" Create all (2^n_exps) binary selection masks for this number of experiments.\n",
    "    E.g. for 3 experiments:\n",
    "    False, False, False\n",
    "    False, False, True\n",
    "    False, True, False\n",
    "    False, True, True\n",
    "    True, False, False\n",
    "    True, False, True\n",
    "    True, True, False\n",
    "    True, True, True\"\"\" \n",
    "    all_masks = np.array([[False] * n_exps] * (2 ** n_exps))\n",
    "    i_block_size = all_masks.shape[0] // 2 \n",
    "    for i_col in range(0,all_masks.shape[1]):\n",
    "        for i_row in range(0,all_masks.shape[0], i_block_size * 2):\n",
    "            all_masks[i_row:i_row+i_block_size,i_col] = [[True]] * i_block_size\n",
    "        i_block_size //= 2\n",
    "    return all_masks\n",
    "    \n",
    "def _compute_diffs(a, b, all_masks):\n",
    "    # first add \"first set\" part\n",
    "    # positive labels from a\n",
    "    # and negative labels from b\n",
    "    diffs = all_masks * a\n",
    "    diffs += (1 - all_masks) * b\n",
    "    # subtract \"second set\" part\n",
    "    # negative labels from a\n",
    "    # positive labels from b\n",
    "    diffs -= (1 - all_masks) * a\n",
    "    diffs -= all_masks * b\n",
    "    return np.mean(diffs, axis=1)\n",
    "\n",
    "def pairwise_compare_frame(df, with_p_vals=False, result_cols=('test', 'time', 'train',\n",
    "        'test_sample', 'train_sample'), compare_col='test'):\n",
    "    table_vals = []\n",
    "    table_indices = []\n",
    "    param_keys = set(df.keys()) - set(list(result_cols))\n",
    "    for key in param_keys:\n",
    "        if key == 'dataset_filename' or key == 'test_filename' or key == 'subject_id':\n",
    "            continue\n",
    "        possible_vals = df[key].unique()\n",
    "        for i_value_a in range(0, len(possible_vals) - 1):\n",
    "            for i_value_b in range(i_value_a + 1, len(possible_vals)):\n",
    "                val_a = possible_vals[i_value_a]\n",
    "                val_b = possible_vals[i_value_b]\n",
    "                frame_1 = df[df[key] == val_a]\n",
    "                frame_2 = df[df[key] == val_b]\n",
    "                other_param_keys = list(param_keys - set([key]))\n",
    "                joined_frame = frame_1.merge(frame_2, on=other_param_keys)\n",
    "                if joined_frame.size == 0:\n",
    "                    continue\n",
    "                accuracies_a = np.array(joined_frame[compare_col + '_x'],\n",
    "                    dtype=np.float64)\n",
    "                accuracies_b = np.array(joined_frame[compare_col + '_y'],\n",
    "                    dtype=np.float64)\n",
    "                mean_a = np.mean(accuracies_a)\n",
    "                mean_b = np.mean(accuracies_b)\n",
    "                # Always put better value first in table\n",
    "                if mean_a >= mean_b:\n",
    "                    accuracies_1 = accuracies_a\n",
    "                    accuracies_2 = accuracies_b\n",
    "                    mean_1 = mean_a \n",
    "                    mean_2 = mean_b \n",
    "                    val_1 = val_a\n",
    "                    val_2 = val_b\n",
    "                else:\n",
    "                    accuracies_1 = accuracies_b\n",
    "                    accuracies_2 = accuracies_a\n",
    "                    mean_1 = mean_b \n",
    "                    mean_2 = mean_a \n",
    "                    val_1 = val_b\n",
    "                    val_2 = val_a\n",
    "                if with_p_vals:\n",
    "                    if len(accuracies_1) <= 18:\n",
    "                        diff_perm = perm_mean_diff_test(accuracies_1,\n",
    "                            accuracies_2) * 100\n",
    "                    elif len(accuracies_1) <= 62:\n",
    "                        diff_perm = perm_mean_diff_test(accuracies_1,\n",
    "                            accuracies_2, n_diffs=2**17) * 100\n",
    "                    else:\n",
    "                        _, diff_perm = wilcoxon(accuracies_1,\n",
    "                            accuracies_2)\n",
    "                        diff_perm *= 100\n",
    "\n",
    "                diffs = accuracies_2 - accuracies_1\n",
    "                diff_std = np.std(diffs)\n",
    "                diff_mean = np.mean(diffs)\n",
    "                this_vals = [len(accuracies_1), str(val_1), str(val_2),\n",
    "                    mean_1, mean_2, diff_mean, diff_std]\n",
    "                if with_p_vals:\n",
    "                    this_vals.append(diff_perm)\n",
    "                table_vals.append(this_vals)\n",
    "                table_indices.append(key)\n",
    "\n",
    "    if len(table_vals) == 0:\n",
    "        return None\n",
    "    table_vals = np.array(table_vals)\n",
    "    compare_headers = ['n_exp', 'val_1', 'val_2', 'acc_1', 'acc_2',\n",
    "                       'diff', 'std']\n",
    "    if with_p_vals:\n",
    "        compare_headers.append('p_val')\n",
    "    compare_frame = pd.DataFrame(table_vals, columns=compare_headers,  \n",
    "                                 index=(table_indices))\n",
    "    compare_frame = to_numeric_where_possible(compare_frame)\n",
    "    compare_frame = round_numeric_columns(compare_frame, 1)\n",
    "    return compare_frame\n",
    "\n",
    "result_cols = ['runtime', 'test_sample_misclass', 'train_misclass', 'valid_sample_misclass', 'test_misclass', \n",
    "               'train_sample_misclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/final-smac//')\n",
    "\n",
    "\n",
    "df = df[df.finished == 1]\n",
    "\n",
    "for key in ('sensitivity', 'specificity', 'auc'):\n",
    "    for setname in ( 'valid', ):\n",
    "        if (setname + '_' + key) in df.columns:\n",
    "            df = df.drop(setname + '_' + key, axis=1)\n",
    "\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "remove_columns_with_same_value(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_df = df[(df.input_time_length == 1200) & \n",
    "               ((df.model_name == 'deep_smac') | (df.model_name == 'shallow_deep_smac'))]\n",
    "\n",
    "for key in ('test_misclass', 'test_sensitivity', 'test_specificity', 'test_sample_misclass'):\n",
    "    val = np.mean(this_df[key]) * 100\n",
    "    if 'misclass' in key:\n",
    "        val = 100 - val\n",
    "    print(np.round(val,1))\n",
    "print(len(this_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_df = df[(df.input_time_length == 6000) & \n",
    "               ((df.model_name == 'deep_smac') | (df.model_name == 'shallow_deep_smac'))]\n",
    "\n",
    "for key in ('test_misclass', 'test_sensitivity', 'test_specificity', 'test_sample_misclass'):\n",
    "    val = np.mean(this_df[key]) * 100\n",
    "    if 'misclass' in key:\n",
    "        val = 100 - val\n",
    "    print(np.round(val,1))\n",
    "print(len(this_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_df = df[(df.input_time_length == 1200) & \n",
    "               (df.model_name == 'shallow_smac')]\n",
    "\n",
    "for key in ('test_misclass', 'test_sensitivity', 'test_specificity', 'test_sample_misclass'):\n",
    "    val = np.mean(this_df[key]) * 100\n",
    "    if 'misclass' in key:\n",
    "        val = 100 - val\n",
    "    print(np.round(val,1))\n",
    "print(len(this_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_df = df[(df.input_time_length == 6000) & \n",
    "               (df.model_name == 'shallow_smac')]\n",
    "\n",
    "for key in ('test_misclass', 'test_sensitivity', 'test_specificity', 'test_sample_misclass'):\n",
    "    val = np.mean(this_df[key]) * 100\n",
    "    if 'misclass' in key:\n",
    "        val = 100 - val\n",
    "    print(np.round(val,1))\n",
    "print(len(this_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished: 0 1 2\n",
    "Started: 3 4 5\n",
    "3 possibly crashing?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/smac-deep4/sacred/')\n",
    "df = df[df.finished == 1]\n",
    "df = df.fillna('-')\n",
    "df = df.drop('seed', axis=1)\n",
    "df = remove_columns_with_same_value(df)\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "df = remove_columns_with_same_value(df)\n",
    "print(len(df))\n",
    "df = df.rename(columns=dict(shrink_the_spikes='shrink',\n",
    "                            channel_standardize='chan_std',\n",
    "                            low_cut_hz='low_hz',\n",
    "                            max_abs_val='max_val',\n",
    "                            high_cut_hz='high_hz',\n",
    "                            moving_demean='m_mean',\n",
    "                            moving_standardize='m_std')).drop(['train_loss', 'valid_loss',\n",
    "                                                       'test_loss', 'valid_misclass',\n",
    "                                                       ], axis=1)\n",
    "df.test_misclass = df.test_misclass * 100\n",
    "\n",
    "df = mean_identical_exps(df,result_cols)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns_with_same_value(df[(df.split_first_layer == 1.0) \n",
    "                                 & (df.n_filters_start == 32.0) &\n",
    "                                 (df.filter_time_length == 21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.split_first_layer == 1.0) \n",
    "                                 & (df.n_filters_start == 32.0) &\n",
    "                                 (df.filter_time_length == 21)].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_level_order = ['split_first_layer', 'n_filters_start', 'n_filters_factor',\n",
    "                       'filter_time_length', 'filter_length_2', 'filter_length_3', 'filter_length_4',\n",
    "                       'final_conv_length',\n",
    "                       'pool_time_length', 'pool_time_stride',\n",
    "                       'first_nonlin', 'first_pool_mode', \n",
    "                       'first_pool_nonlin', \n",
    "                       'later_nonlin', 'later_pool_mode', 'later_pool_nonlin', \n",
    "                       'drop_prob', 'model_constraint', 'double_time_convs',\n",
    "                       'do_batch_norm']\n",
    "\n",
    "df_avg = dataset_averaged_frame(df,\n",
    "                                'i_test_fold',result_cols + ['n_exp']).sort_values(by=('test_misclass', 'mean'))\n",
    "df_avg = df_avg.reorder_levels(new_level_order)\n",
    "df_avg = df_avg[df_avg[('runtime', 'len')] > 6]\n",
    "df_avg = df_avg.ix[:,['test_sample_misclass', 'test_misclass', 'runtime', 'train_sample_misclass', \n",
    "                      'train_misclass', 'n_exp']]\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = dataset_averaged_frame(df,\n",
    "                                'i_test_fold',result_cols + ['n_exp']).sort_values(by=('test_misclass', 'mean'))\n",
    "\n",
    "plt.hist(df_avg[('runtime', 'len')],bins=np.arange(0.5,10.6,1))\n",
    "plt.xticks(range(11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_avg[('test_sample_misclass', 'mean')],\n",
    "            df_avg[('test_misclass', 'mean')],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_avg[df_avg[('runtime', 'len')] > 6][('test_sample_misclass', 'mean')],\n",
    "            df_avg[df_avg[('runtime', 'len')] > 6][('test_misclass', 'mean')],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(df_avg[df_avg[('runtime', 'len')] > 6][('test_sample_misclass', 'mean')]) * 100)\n",
    "plt.plot(np.array(df_avg[df_avg[('runtime', 'len')] > 6][('test_misclass', 'mean')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(df_avg[('test_sample_misclass', 'mean')]) * 100)\n",
    "plt.plot(np.array(df_avg[('test_misclass', 'mean')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/smac-shallow/sacred//')\n",
    "df = df[df.finished == 1]\n",
    "df = df.fillna('-')\n",
    "df = df.drop('seed', axis=1)\n",
    "df = remove_columns_with_same_value(df)\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "df = remove_columns_with_same_value(df)\n",
    "print(len(df))\n",
    "df = df.rename(columns=dict(shrink_the_spikes='shrink',\n",
    "                            channel_standardize='chan_std',\n",
    "                            low_cut_hz='low_hz',\n",
    "                            max_abs_val='max_val',\n",
    "                            high_cut_hz='high_hz',\n",
    "                            moving_demean='m_mean',\n",
    "                            moving_standardize='m_std')).drop(['train_loss', 'valid_loss',\n",
    "                                                       'test_loss', 'valid_misclass',\n",
    "                                                       ], axis=1)\n",
    "df.test_misclass = df.test_misclass * 100\n",
    "\n",
    "df = mean_identical_exps(df,result_cols)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns_with_same_value(df[(df.split_first_layer == 1.0) \n",
    "                                 & (df.n_filters_time == 24.0) &\n",
    "                                 (df.n_filters_spat == 73) &\n",
    "                                 (np.round(df.drop_prob,6) == 0.328794) &\n",
    "                                 (df.conv_nonlin == 'identity')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.split_first_layer == 1.0) \n",
    "                                 & (df.n_filters_time == 24.0) &\n",
    "                                 (df.n_filters_spat == 73) &\n",
    "                                 (np.round(df.drop_prob,6) == 0.328794) &\n",
    "                                 (df.conv_nonlin == 'identity')].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_level_order = ['split_first_layer', 'n_filters_time', \n",
    "                   'n_filters_spat',\n",
    "                   'filter_time_length', \n",
    "                   'conv_nonlin', \n",
    "                   'pool_mode',\n",
    "                   'pool_time_length', 'pool_time_stride', \n",
    "                   'pool_nonlin', \n",
    "                   'final_conv_length',\n",
    "                   'drop_prob', 'model_constraint',\n",
    "                   'do_batch_norm']\n",
    "df_avg = dataset_averaged_frame(df,\n",
    "                                'i_test_fold',\n",
    "                                result_cols + ['n_exp']).sort_values(by=('test_misclass', 'mean'))\n",
    "df_avg = df_avg.reorder_levels(new_level_order)\n",
    "df_avg = remove_indices_with_same_value(df_avg[df_avg[('runtime', 'len')] > 6])\n",
    "df_avg = df_avg.ix[:,['test_sample_misclass', 'test_misclass', 'runtime', 'train_sample_misclass', 'train_misclass', 'n_exp']]\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = dataset_averaged_frame(df,\n",
    "                                'i_test_fold',result_cols + ['n_exp']).sort_values(by=('test_misclass', 'mean'))\n",
    "\n",
    "plt.hist(df_avg[('runtime', 'len')],bins=np.arange(0.5,10.6,1))\n",
    "plt.xticks(range(11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_avg[('test_sample_misclass', 'mean')],\n",
    "            df_avg[('test_misclass', 'mean')],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df_avg[df_avg[('runtime', 'len')] > 6][('test_sample_misclass', 'mean')],\n",
    "            df_avg[df_avg[('runtime', 'len')] > 6][('test_misclass', 'mean')],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(df_avg[df_avg[('runtime', 'len')] > 6][('test_sample_misclass', 'mean')]) * 100)\n",
    "plt.plot(np.array(df_avg[df_avg[('runtime', 'len')] > 6][('test_misclass', 'mean')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(df_avg[('test_sample_misclass', 'mean')]) * 100)\n",
    "plt.plot(np.array(df_avg[('test_misclass', 'mean')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
