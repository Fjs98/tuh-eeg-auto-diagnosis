{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from glob import glob\n",
    "import os.path\n",
    "\n",
    "main_folder = '/home/schirrmr/data/auto-diagnosis/tuh-eeg/reports/edf/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_dict(filetext):\n",
    "    filetext = filetext.replace('\\t', '')\n",
    "    lines = filetext.split('\\n')\n",
    "    current_tag = None\n",
    "    current_text = ''\n",
    "    tag_to_text = dict()\n",
    "    for line in lines:\n",
    "        new_tag_starts = re.match('[A-Z \\t]+:', line)\n",
    "        if new_tag_starts:\n",
    "            if current_tag is not None:\n",
    "                tag_to_text[current_tag] = current_text\n",
    "            current_tag =  new_tag_starts.group(0)[:-1]\n",
    "            current_text = line[len(current_tag) + 1:]\n",
    "            current_tag = current_tag.strip()\n",
    "        else:\n",
    "            current_text += line\n",
    "        assert current_tag is not None\n",
    "    tag_to_text[current_tag] = current_text\n",
    "    return tag_to_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filenames = glob(os.path.join(main_folder , '**/*.txt'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_parse_failure = 0\n",
    "n_unicode_failure = 0\n",
    "all_dicts = []\n",
    "for i_filename, filename in enumerate(filenames):\n",
    "    if i_filename % 100 == 0:\n",
    "        print(\"Processing file {:d} of {:d}, {:.2f}%...\".format(i_filename + 1,\n",
    "                                                               len(filenames),\n",
    "                                                               (100 * i_filename) / float(len(filenames))))\n",
    "    \n",
    "    try:\n",
    "        filetext = open(filename, 'r').read()\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Unicode failure\")\n",
    "        n_unicode_failure += 1\n",
    "        continue\n",
    "    try:\n",
    "        report_dict = extract_dict(filetext)\n",
    "    except AssertionError:\n",
    "        print(\"Failure with {:s}\".format(filetext))\n",
    "        n_parse_failure += 1\n",
    "        continue\n",
    "    all_dicts.append(report_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = [set(d.keys()) for d in all_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.union(*keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_texts = []\n",
    "for i_filename, filename in enumerate(filenames):\n",
    "    if i_filename % 100 == 0:\n",
    "        print(\"Processing file {:d} of {:d}, {:.1f}%...\".format(i_filename + 1,\n",
    "                                                               len(filenames),\n",
    "                                                               (100 * i_filename) / float(len(filenames))))\n",
    "    filetext= open(filename, 'r', encoding='iso-8859-1').read()\n",
    "    all_file_texts.append(filetext)\n",
    "    #try:\n",
    "    #    filetext = open(filename, 'r').read()\n",
    "    #except UnicodeDecodeError:\n",
    "    #    filetext= open(filename, 'r', encoding='iso-8859-1')\n",
    "    #    n_unicode_failure += 1\n",
    "    #    continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dicts = [dict(text=text, filename=filename.replace(main_folder,''), nr=nr)\n",
    "             for nr, filename, text in\n",
    "      zip(range(len(all_file_texts)), filenames, all_file_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(all_dicts[:100], open('auto-eeg-data-small.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(all_dicts, open('auto-eeg-data.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat auto-eeg-data.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
