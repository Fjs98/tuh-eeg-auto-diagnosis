{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/auto-diagnosis/')\n",
    "%cd /home/schirrmr/\n",
    "# switch to cpu\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png' \n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 3.0)\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('DEBUG')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "from numpy.random import RandomState\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "from autodiag.perturbation import combine_covs, combine_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "n_recordings = None#20 # only if I want to limit it\n",
    "    \n",
    "folder = 'data/models/pytorch/auto-diag/less-minutes/12/'\n",
    "from hyperoptim.rerun import rerun_exp\n",
    "ex = rerun_exp(folder, update_params=dict(only_return_exp=True), \n",
    "          save_experiment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ex.result\n",
    "n_stride = exp.iterator.n_preds_per_input#5400\n",
    "n_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasattr(exp, 'test_dataset')\n",
    "if n_recordings is not None:\n",
    "    exp.test_dataset.n_recordings = n_recordings\n",
    "test_X, test_y = exp.test_dataset.load()\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "test_set = SignalAndTarget(test_X, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = test_set.y#data/models/pytorch/auto-diag/less-minutes/12/test_trial_labels.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/models/pytorch/auto-diag/less-minutes/12/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds_per_trial = np.load(os.path.join(folder,'test_crop_preds.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_per_trial = [np.concatenate(p, axis=1) for p in preds_per_trial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_receptive_field = exp.iterator.input_time_length -n_stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_trial_accs = []\n",
    "all_crop_accs = []\n",
    "minute_steps = (0.2,1,2,4,8,16)\n",
    "for minutes in minute_steps:\n",
    "    n_stop = int(round(minutes * 60 * 100 - n_receptive_field + 1))\n",
    "    print(\"n_stop\", n_stop)\n",
    "    reduced_preds = [p[:,:n_stop] for p in preds_per_trial]\n",
    "    lengths = np.array([p.shape[1] for p in reduced_preds])\n",
    "    assert np.max(lengths) == n_stop\n",
    "    mean_preds_per_trial = [np.mean(preds, axis=(1)) for preds in\n",
    "                                reduced_preds]\n",
    "    accuracy = np.mean(np.argmax(mean_preds_per_trial, axis=1) == labels)\n",
    "    all_trial_accs.append(accuracy)\n",
    "    print(\"Accuracy for {:.0f}: {:.1f}\".format(minutes, accuracy * 100))\n",
    "    \n",
    "    crop_accs = [np.mean(i == np.argmax(p, axis=0)) for i,p in zip(labels, reduced_preds)]\n",
    "    crop_acc = np.sum(crop_accs * lengths / np.sum(lengths))\n",
    "    print(\"CropAcc. for {:.0f}: {:.1f}\".format(minutes, crop_acc * 100))\n",
    "    all_crop_accs.append(crop_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(folder, 'reduced_time_accuracies.npy')\n",
    "log.info(\"Save to {:s}\".format(filename))\n",
    "\n",
    "np.save(filename, np.array([minute_steps, all_trial_accs, all_crop_accs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "crop_preds = np.load(os.path.join(folder,'test_crop_preds.npy'))\n",
    "trial_preds = [np.concatenate(c[:-1], axis=1) for c in crop_preds]\n",
    "max_shape = np.max([list(t.shape) for t in trial_preds], axis=0)\n",
    "preds_padded = np.full((len(trial_preds), max_shape[1], max_shape[0]),np.nan)\n",
    "for i_trial, trial_pred in enumerate(trial_preds):\n",
    "    preds_padded[i_trial,:trial_pred.shape[1]] =  trial_pred.T\n",
    "\n",
    "nan_mask = (0 * preds_padded + 1)[:,:,0]\n",
    "\n",
    "labels_padded = np.argmax(preds_padded, axis=2)\n",
    "\n",
    "pred_correct = labels_padded == labels[:,None]\n",
    "\n",
    "pred_correct = pred_correct * nan_mask\n",
    "\n",
    "correct_timecourse = np.nanmean(pred_correct, axis=0) * 100\n",
    "correct_std_timecourse = np.nanstd(pred_correct, axis=0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((600 + np.arange(len(correct_timecourse))) / 100.0,correct_timecourse)\n",
    "plt.fill_between((600 + np.arange(len(correct_timecourse))) / 100.0,\n",
    "                 correct_timecourse - correct_std_timecourse / np.sqrt(len(pred_correct)),\n",
    "                 correct_timecourse + correct_std_timecourse / np.sqrt(len(pred_correct)),\n",
    "            alpha=0.3)\n",
    "plt.xlabel('Time [sec]', fontsize=14)\n",
    "plt.ylabel('Accuracy [%]', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
