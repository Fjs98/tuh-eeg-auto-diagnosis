{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/auto-diagnosis/')\n",
    "%cd /home/schirrmr/\n",
    "# switch to cpu\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png' \n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 3.0)\n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('DEBUG')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "\n",
    "from braindecode.torch_ext.util import np_to_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sorted_file_names, train_labels = get_all_sorted_file_names_and_labels('train')\n",
    "print(len(train_sorted_file_names))\n",
    "\n",
    "train_infos = [get_info_with_mne(fname) for fname in train_sorted_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sorted_file_names, eval_labels = get_all_sorted_file_names_and_labels('eval')\n",
    "\n",
    "print(len(eval_sorted_file_names))\n",
    "\n",
    "eval_infos = [get_info_with_mne(fname) for fname in eval_sorted_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#edf_file, sampling_frequency, n_samples, n_signals, signal_names, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array([info[5] for info in eval_infos]) / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array([info[1] for info in eval_infos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autodiag.dataset import DiagnosisSet, get_all_sorted_file_names_and_labels\n",
    "\n",
    "from autoeeglukas.utils.my_io import get_info_with_mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "from braindecode.datautil.iterators import get_balanced_batches\n",
    "\n",
    "def create_set(X, y, inds):\n",
    "    \"\"\"\n",
    "    X list and y nparray\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    new_X = []\n",
    "    for i in inds:\n",
    "        new_X.append(X[i])\n",
    "    new_y = y[inds]\n",
    "    return SignalAndTarget(new_X, new_y)\n",
    "\n",
    "class TrainValidTestSplitter(object):\n",
    "    def __init__(self, n_folds, i_test_fold):\n",
    "        self.n_folds = n_folds\n",
    "        self.i_test_fold = i_test_fold\n",
    "\n",
    "    def split(self, X, y):\n",
    "        if len(X) < self.n_folds:\n",
    "            raise ValueError(\"Less Trials: {:d} than folds: {:d}\".format(\n",
    "                len(X), self.n_folds\n",
    "            ))\n",
    "        folds = get_balanced_batches(len(X), None, False,\n",
    "                                     n_batches=self.n_folds)\n",
    "        test_inds = folds[self.i_test_fold]\n",
    "        valid_inds = folds[self.i_test_fold - 1]\n",
    "        all_inds = list(range(len(X)))\n",
    "        train_inds = np.setdiff1d(all_inds, np.union1d(test_inds, valid_inds))\n",
    "        assert np.intersect1d(train_inds, valid_inds).size == 0\n",
    "        assert np.intersect1d(train_inds, test_inds).size == 0\n",
    "        assert np.intersect1d(valid_inds, test_inds).size == 0\n",
    "        assert np.array_equal(np.sort(\n",
    "            np.union1d(train_inds, np.union1d(valid_inds, test_inds))),\n",
    "            all_inds)\n",
    "\n",
    "        train_set = create_set(X, y, train_inds)\n",
    "        valid_set = create_set(X, y, valid_inds)\n",
    "        test_set = create_set(X, y, test_inds)\n",
    "\n",
    "        return train_set, valid_set, test_set\n",
    "\n",
    "\n",
    "class TrainValidSplitter(object):\n",
    "    def __init__(self, n_folds, i_valid_fold):\n",
    "        self.n_folds = n_folds\n",
    "        self.i_valid_fold = i_valid_fold\n",
    "\n",
    "    def split(self, X, y):\n",
    "        if len(X) < self.n_folds:\n",
    "            raise ValueError(\"Less Trials: {:d} than folds: {:d}\".format(\n",
    "                len(X), self.n_folds\n",
    "            ))\n",
    "        folds = get_balanced_batches(len(X), None, False,\n",
    "                                     n_batches=self.n_folds)\n",
    "        valid_inds = folds[self.i_valid_fold]\n",
    "        all_inds = list(range(len(X)))\n",
    "        train_inds = np.setdiff1d(all_inds, valid_inds)\n",
    "        assert np.intersect1d(train_inds, valid_inds).size == 0\n",
    "        assert np.array_equal(np.sort(np.union1d(train_inds, valid_inds)),\n",
    "            all_inds)\n",
    "\n",
    "        train_set = create_set(X, y, train_inds)\n",
    "        valid_set = create_set(X, y, valid_inds)\n",
    "        return train_set, valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_on_eval = True\n",
    "only_return_exp = False\n",
    "n_recordings = 10\n",
    "max_recording_mins = 35\n",
    "preproc_functions = []\n",
    "n_folds = 10\n",
    "i_test_fold = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiagnosisSet(n_recordings=n_recordings,\n",
    "                    max_recording_mins=max_recording_mins,\n",
    "                    preproc_functions=preproc_functions,\n",
    "                      train_or_eval='train')\n",
    "if test_on_eval:\n",
    "    test_set = DiagnosisSet(n_recordings=n_recordings,\n",
    "                           max_recording_mins=None,\n",
    "                           preproc_functions=preproc_functions,\n",
    "                               train_or_eval='eval')\n",
    "if not only_return_exp:\n",
    "    X,y = dataset.load()\n",
    "    if test_on_eval:\n",
    "        test_X, test_y = test_set.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_on_eval:\n",
    "    splitter = TrainValidTestSplitter(n_folds, i_test_fold,)\n",
    "else:\n",
    "    splitter = TrainValidSplitter(n_folds, i_valid_fold=i_test_fold)\n",
    "if not only_return_exp:\n",
    "    if not test_on_eval:\n",
    "        train_set, valid_set, test_set = splitter.split(X,y)\n",
    "    else:\n",
    "        train_set, valid_set = splitter.split(X,y)\n",
    "        test_set = SignalAndTarget(test_X, test_y)\n",
    "    \n",
    "del X,y\n",
    "del test_X, test_y\n",
    "    \n",
    "    \n",
    "# if not test on eval\n",
    "#exp.test_set = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
