{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/auto-diagnosis/')\n",
    "%cd /home/schirrmr/\n",
    "# switch to cpu\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 4.0)\n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('DEBUG')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "\n",
    "from braindecode.torch_ext.util import np_to_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.sys.path.insert(0, '/home/schirrmr/code/auto-diagnosis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autodiag.dataset import load_data, DiagnosisSet, get_all_sorted_file_names_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_file_names, labels = get_all_sorted_file_names_and_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "rng = RandomState(384734)\n",
    "in_var = np_to_var(rng.randn(3,5,18,2), dtype=np.float32)\n",
    "percentile = th.kthvalue(th.abs(in_var.view(-1)), int(0.95 * in_var.numel()))\n",
    "cutoff = percentile * 2\n",
    "# store das die ganze zeit, und beim forward pass clampe die werte dann zu +-cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = np.load(\n",
    "            '/home/schirrmr/code/auto-diagnosis/sorted-recording-lengths.npy')\n",
    "mask = lengths < 35 * 60\n",
    "cleaned_file_names = np.array(all_file_names)[mask]\n",
    "cleaned_labels = labels[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sec_to_cut = 60\n",
    "preproc_functions = []\n",
    "duration_recording_mins = 3\n",
    "preproc_functions.append(\n",
    "    lambda data, fs: (data[:, int(sec_to_cut * fs):-int(\n",
    "        sec_to_cut * fs)], fs))\n",
    "preproc_functions.append(\n",
    "    lambda data, fs: (data[:, :int(duration_recording_mins * 60 * fs)], fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def compute_min_max_diffs(x, window_len, cuda):\n",
    "    x_var = np_to_var(x)\n",
    "    if x_var.dim() == 2:\n",
    "        x_var = x_var.unsqueeze(0)\n",
    "    if cuda:\n",
    "        x_var = x_var.cuda()\n",
    "\n",
    "    maxs = F.max_pool1d(x_var,window_len, stride=1)\n",
    "    mins = F.max_pool1d(-x_var,window_len, stride=1)\n",
    "\n",
    "    diffs = maxs + mins\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inds = np.int32(np.arange(10))\n",
    "valid_inds = np.int32(np.arange(10,12))\n",
    "test_inds = np.int32(np.arange(12,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import resampy\n",
    "sec_to_cut = 60\n",
    "preproc_functions = []\n",
    "duration_recording_mins = 3\n",
    "sampling_freq = 100\n",
    "preproc_functions.append(\n",
    "    lambda data, fs: (data[:, int(sec_to_cut * fs):-int(\n",
    "        sec_to_cut * fs)], fs))\n",
    "preproc_functions.append(\n",
    "    lambda data, fs: (data[:, :int(duration_recording_mins * 60 * fs)], fs))\n",
    "preproc_functions.append(lambda data, fs: (resampy.resample(data, fs,\n",
    "                                                            sampling_freq,\n",
    "                                                            axis=1,\n",
    "                                                            filter='kaiser_fast'),\n",
    "                                           sampling_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import resampy\n",
    "def preproc_set_further(the_set, start_fs, preproc_functions):\n",
    "    the_set = deepcopy(the_set)\n",
    "    new_X = []\n",
    "    for x in the_set.X:\n",
    "        fs = start_fs\n",
    "        for preproc_fn in preproc_functions:\n",
    "            x, fs = preproc_fn(x, fs)\n",
    "        new_X.append(x)\n",
    "    the_set.X = new_X\n",
    "    return the_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "def create_set(inds):\n",
    "    X = []\n",
    "    for i in inds:\n",
    "        log.info(\"Load {:s}\".format(cleaned_file_names[i]))\n",
    "        x = load_data(cleaned_file_names[i], preproc_functions)\n",
    "        X.append(x)\n",
    "    y = cleaned_labels[inds].astype(np.int64)\n",
    "    return SignalAndTarget(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from autodiag.iterator import ModifiedIterator\n",
    "from autodiag.batch_modifier import RemoveMinMaxDiff\n",
    "\n",
    "        \n",
    "from autodiag.clean import set_jumps_to_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = create_set(train_inds)\n",
    "valid_set = create_set(valid_inds)\n",
    "test_set = create_set(test_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autodiag.twopathnet import create_two_path_net\n",
    "\n",
    "n_start_filters = 30\n",
    "in_chans = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preproc_fn = []#lambda data, fs: (remove_jumps(data,200,400,True,True), fs)]\n",
    "start_fs = 100\n",
    "#new_preproc_fn.append(lambda data, fs : (np.clip(data,-200,200),fs))\n",
    "new_train_set = preproc_set_further(train_set, start_fs, new_preproc_fn)\n",
    "new_valid_set = preproc_set_further(valid_set, start_fs, new_preproc_fn)\n",
    "new_test_set = preproc_set_further(test_set, start_fs, new_preproc_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from autodiag.threepathnet import create_multi_start_path_net\n",
    "cuda = True\n",
    "\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "input_time_length = 3000\n",
    "in_chans = 21\n",
    "n_start_filters = 30\n",
    "model = create_two_path_net(in_chans=in_chans, n_start_filters=n_start_filters,\n",
    "                           later_strides=6)\n",
    "\n",
    "\n",
    "test_input = np_to_var(\n",
    "    np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "model(test_input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np_to_var(\n",
    "    np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "x = test_input\n",
    "for name, module in model.named_children():\n",
    "    x = module(x)\n",
    "    print(name, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters())#(model.parameters(), grad_clip_std_factor=2)#optim.Adam(model.parameters())\n",
    "log.info(\"Model:\\n{:s}\".format(str(model)))\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "n_preds_per_input = input_time_length // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autodiag.monitors import CroppedNonDenseTrialMisclassMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "from braindecode.experiments.monitors import (RuntimeMonitor, LossMonitor,\n",
    "                                              CroppedTrialMisclassMonitor,\n",
    "                                              MisclassMonitor)\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "\n",
    "batch_size = 32\n",
    "log.info(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "iterator = CropsFromTrialsIterator(batch_size=batch_size,\n",
    "                                   input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0],\n",
    "                                                  targets)\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedNonDenseTrialMisclassMonitor(input_time_length, n_preds_per_input),\n",
    "            RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "batch_modifier = RemoveMinMaxDiff(300,clip_max_abs=True, set_zero=True)#None\n",
    "iterator = ModifiedIterator(iterator, batch_modifier)\n",
    "batch_modifier=None\n",
    "exp = Experiment(model, new_train_set, new_valid_set, new_test_set, iterator,\n",
    "                 loss_function, optimizer, model_constraint,\n",
    "                 monitors, stop_criterion,\n",
    "                 remember_best_column='valid_misclass',\n",
    "                 run_after_early_stop=False, batch_modifier=batch_modifier, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.setup_training()\n",
    "exp.run_until_early_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(exp.epochs_df.train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(exp.epochs_df.train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(exp.epochs_df.train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(exp.epochs_df.train_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
