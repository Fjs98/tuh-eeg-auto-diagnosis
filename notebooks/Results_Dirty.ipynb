{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "%cd /home/schirrmr/\n",
    "# switch to cpu\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 3.0)\n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('DEBUG')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "from hyperoptim.results import load_data_frame, remove_columns_with_same_value, dataset_averaged_frame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.morestats import wilcoxon\n",
    "import random\n",
    "\n",
    "def to_numeric_where_possible(df):\n",
    "    df = df.copy(deep=True)\n",
    "    for col in df.columns:\n",
    "        df.loc[:,col] = pd.to_numeric(df.loc[:,col], errors='ignore')\n",
    "    return df\n",
    "\n",
    "def round_numeric_columns(df, decimals):\n",
    "    df = df.copy(deep=True)\n",
    "    tmp = df.select_dtypes(include=[np.number], exclude=[np.timedelta64])\n",
    "    df.loc[:, tmp.columns] = np.round(tmp, decimals)\n",
    "    return df\n",
    "\n",
    "def perm_mean_diffs_sampled(a, b, n_diffs=None):\n",
    "    \"\"\"Compute differences between all permutations of  labels.\n",
    "    Version that samples.\n",
    "    Parameters\n",
    "    --------------\n",
    "    a: list or numpy array\n",
    "    b: list or numpy array\n",
    "    n_diffs: int\n",
    "        How many diffs/samples to compute.\n",
    "    Returns\n",
    "    -------\n",
    "    all_diffs: 1d-array of float\n",
    "        Sampled mean differences.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_exps = len(a)\n",
    "    all_bit_masks = [2 ** n for n in range(n_exps-1,-1,-1)]\n",
    "    if n_diffs is None:\n",
    "        n_diffs = 2**n_exps\n",
    "        i_all_masks = range(n_diffs)\n",
    "    else:\n",
    "        random.seed(39483948)\n",
    "        # take samples of all masks, always add identity mask\n",
    "        i_all_masks = random.sample(range(0,2**n_exps-1), n_diffs - 1)\n",
    "        i_all_masks = i_all_masks + [(2**n_exps)-1]\n",
    "        # verification this is actually identity mask for code below:\n",
    "        test_i_mask = i_all_masks[-1]\n",
    "        test_mask = (np.bitwise_and(test_i_mask, all_bit_masks) > 0) * 2 - 1\n",
    "        assert np.array_equal(a - b, (test_mask * a)  -test_mask * b)\n",
    "\n",
    "        \n",
    "    all_diffs = np.float32(np.ones(n_diffs) * np.nan)\n",
    "    for i_diff, i_mask in enumerate(i_all_masks):\n",
    "        # masks has -1s and 1s,\n",
    "        # 1 interpretable as\n",
    "        # correct value selected\n",
    "        # -1 as randomly flipped value/\"incorrect\" value selected\n",
    "        # *2 makes values between 2 and 0, then -1 to make \n",
    "        # values between 1 and -1\n",
    "        mask = (np.bitwise_and(i_mask, all_bit_masks) > 0) * 2 - 1\n",
    "        # mean later by dividing by n_exp\n",
    "        # seems to be a little bit faster that way\n",
    "        diff = np.sum((mask * a)  -mask * b)\n",
    "        all_diffs[i_diff] = diff\n",
    "    all_diffs = all_diffs / float(n_exps)\n",
    "    return all_diffs\n",
    "\n",
    "def perm_mean_diffs(a,b):\n",
    "    \"\"\"Compute differences between all permutations of  labels.\n",
    "    Assumes a and b are paired values,\n",
    "    a are values with label 0 and b with label 1.\n",
    "    Computes mean differences for all possible   \n",
    "    switches of 0 and 1 (but keeping pairs together, i.e.\n",
    "    2 ^ len(a) switches).\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    a: list or numpy array\n",
    "    b: list or numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    diffs: 1d-numpy array\n",
    "        Differences between means of labelled values\n",
    "        for all label-switched values.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    http://www.stat.ncsu.edu/people/lu/courses/ST505/Ch4.pdf#page=10\n",
    "    http://stats.stackexchange.com/a/64215/56289\n",
    "    http://www.jarrodmillman.com/publications/millman2015thesis.pdf ->\n",
    "    https://github.com/statlab/permute python package \n",
    "    (probably, didnt read: http://finzi.psych.upenn.edu/R/library/EnvStats/html/twoSamplePermutationTestLocation.html)\n",
    "    \"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    assert len(a) == len(b)\n",
    "    n_exps = len(a)\n",
    "    all_masks = _create_masks(n_exps)\n",
    "    diffs = _compute_diffs(a, b, all_masks)\n",
    "    return diffs\n",
    "\n",
    "def perm_mean_diff_test(a,b, n_diffs=None):\n",
    "    \"\"\"Return two sided p-value of perm mean diff.\"\"\"\n",
    "    if n_diffs is None:\n",
    "        diffs = perm_mean_diffs(a, b)\n",
    "    else:\n",
    "        diffs = perm_mean_diffs_sampled(a, b, n_diffs)\n",
    "    \n",
    "    actual_diff = np.mean(a - b)\n",
    "    n_samples_as_large_diff = np.sum(np.abs(diffs) >= np.abs(actual_diff))\n",
    "    #if n_diffs is not None:\n",
    "    #    p_val = n_samples_as_large_diff + 1 /\n",
    "    return n_samples_as_large_diff / float(len(diffs))\n",
    "\n",
    "\n",
    "def _create_masks(n_exps):\n",
    "    \"\"\" Create all (2^n_exps) binary selection masks for this number of experiments.\n",
    "    E.g. for 3 experiments:\n",
    "    False, False, False\n",
    "    False, False, True\n",
    "    False, True, False\n",
    "    False, True, True\n",
    "    True, False, False\n",
    "    True, False, True\n",
    "    True, True, False\n",
    "    True, True, True\"\"\" \n",
    "    all_masks = np.array([[False] * n_exps] * (2 ** n_exps))\n",
    "    i_block_size = all_masks.shape[0] // 2 \n",
    "    for i_col in range(0,all_masks.shape[1]):\n",
    "        for i_row in range(0,all_masks.shape[0], i_block_size * 2):\n",
    "            all_masks[i_row:i_row+i_block_size,i_col] = [[True]] * i_block_size\n",
    "        i_block_size //= 2\n",
    "    return all_masks\n",
    "    \n",
    "def _compute_diffs(a, b, all_masks):\n",
    "    # first add \"first set\" part\n",
    "    # positive labels from a\n",
    "    # and negative labels from b\n",
    "    diffs = all_masks * a\n",
    "    diffs += (1 - all_masks) * b\n",
    "    # subtract \"second set\" part\n",
    "    # negative labels from a\n",
    "    # positive labels from b\n",
    "    diffs -= (1 - all_masks) * a\n",
    "    diffs -= all_masks * b\n",
    "    return np.mean(diffs, axis=1)\n",
    "\n",
    "def pairwise_compare_frame(df, with_p_vals=False, result_cols=('test', 'time', 'train',\n",
    "        'test_sample', 'train_sample'), compare_col='test'):\n",
    "    table_vals = []\n",
    "    table_indices = []\n",
    "    param_keys = set(df.keys()) - set(list(result_cols))\n",
    "    for key in param_keys:\n",
    "        if key == 'dataset_filename' or key == 'test_filename' or key == 'subject_id':\n",
    "            continue\n",
    "        possible_vals = df[key].unique()\n",
    "        for i_value_a in range(0, len(possible_vals) - 1):\n",
    "            for i_value_b in range(i_value_a + 1, len(possible_vals)):\n",
    "                val_a = possible_vals[i_value_a]\n",
    "                val_b = possible_vals[i_value_b]\n",
    "                frame_1 = df[df[key] == val_a]\n",
    "                frame_2 = df[df[key] == val_b]\n",
    "                other_param_keys = list(param_keys - set([key]))\n",
    "                joined_frame = frame_1.merge(frame_2, on=other_param_keys)\n",
    "                if joined_frame.size == 0:\n",
    "                    continue\n",
    "                accuracies_a = np.array(joined_frame[compare_col + '_x'],\n",
    "                    dtype=np.float64)\n",
    "                accuracies_b = np.array(joined_frame[compare_col + '_y'],\n",
    "                    dtype=np.float64)\n",
    "                mean_a = np.mean(accuracies_a)\n",
    "                mean_b = np.mean(accuracies_b)\n",
    "                # Always put better value first in table\n",
    "                if mean_a >= mean_b:\n",
    "                    accuracies_1 = accuracies_a\n",
    "                    accuracies_2 = accuracies_b\n",
    "                    mean_1 = mean_a \n",
    "                    mean_2 = mean_b \n",
    "                    val_1 = val_a\n",
    "                    val_2 = val_b\n",
    "                else:\n",
    "                    accuracies_1 = accuracies_b\n",
    "                    accuracies_2 = accuracies_a\n",
    "                    mean_1 = mean_b \n",
    "                    mean_2 = mean_a \n",
    "                    val_1 = val_b\n",
    "                    val_2 = val_a\n",
    "                if with_p_vals:\n",
    "                    if len(accuracies_1) <= 18:\n",
    "                        diff_perm = perm_mean_diff_test(accuracies_1,\n",
    "                            accuracies_2) * 100\n",
    "                    elif len(accuracies_1) <= 62:\n",
    "                        diff_perm = perm_mean_diff_test(accuracies_1,\n",
    "                            accuracies_2, n_diffs=2**17) * 100\n",
    "                    else:\n",
    "                        _, diff_perm = wilcoxon(accuracies_1,\n",
    "                            accuracies_2)\n",
    "                        diff_perm *= 100\n",
    "\n",
    "                diffs = accuracies_2 - accuracies_1\n",
    "                diff_std = np.std(diffs)\n",
    "                diff_mean = np.mean(diffs)\n",
    "                this_vals = [len(accuracies_1), str(val_1), str(val_2),\n",
    "                    mean_1, mean_2, diff_mean, diff_std]\n",
    "                if with_p_vals:\n",
    "                    this_vals.append(diff_perm)\n",
    "                table_vals.append(this_vals)\n",
    "                table_indices.append(key)\n",
    "\n",
    "    if len(table_vals) == 0:\n",
    "        return None\n",
    "    table_vals = np.array(table_vals)\n",
    "    compare_headers = ['n_exp', 'val_1', 'val_2', 'acc_1', 'acc_2',\n",
    "                       'diff', 'std']\n",
    "    if with_p_vals:\n",
    "        compare_headers.append('p_val')\n",
    "    compare_frame = pd.DataFrame(table_vals, columns=compare_headers,  \n",
    "                                 index=(table_indices))\n",
    "    compare_frame = to_numeric_where_possible(compare_frame)\n",
    "    compare_frame = round_numeric_columns(compare_frame, 1)\n",
    "    return compare_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/dirty-data/')\n",
    "df = df[df.finished == 1]\n",
    "df = df.fillna('-')\n",
    "df = df.drop('seed', axis=1)\n",
    "df = remove_columns_with_same_value(df)\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "df = df.drop('max_min_expected', axis=1)\n",
    "df = df[df.max_epochs > 1]\n",
    "df = remove_columns_with_same_value(df)\n",
    "print(len(df))\n",
    "df = df.rename(columns=dict(shrink_the_spikes='shrink',\n",
    "                            channel_standardize='chan_std',\n",
    "                            low_cut_hz='low_hz',\n",
    "                            max_abs_val='max_val',\n",
    "                            channel_demean='chan_mean',\n",
    "                            exp_demean='e_mean',\n",
    "                            exp_standardize='e_std',\n",
    "                            max_min_expected='max_expd',\n",
    "                            max_threshold='max_min_threshold',\n",
    "                            high_cut_hz='high_hz',\n",
    "                            moving_demean='m_mean',\n",
    "                            moving_standardize='m_std')).drop(['train_loss', 'valid_loss',\n",
    "                                                       'test_loss', 'valid_misclass',\n",
    "                                                       ], axis=1)\n",
    "df.test_misclass = df.test_misclass * 100\n",
    "df.test_sample_misclass = df.test_sample_misclass * 100\n",
    "\n",
    "df.sort_values(by='test_sample_misclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_before_stop = df.copy()\n",
    "for exp_nr in df.index:\n",
    "    before_stop_df = np.load('data/models/pytorch/auto-diag/dirty-data/{:d}/before_stop_df.pkl'.format(\n",
    "        exp_nr))\n",
    "    final_vals = before_stop_df.iloc[-1]\n",
    "    for key, val in final_vals.items():\n",
    "        if key in df_before_stop.columns or key == 'valid_misclass':\n",
    "            df_before_stop.ix[exp_nr, key] = val\n",
    "\n",
    "df_before_stop.test_sample_misclass = (df_before_stop.test_sample_misclass + df_before_stop.valid_sample_misclass) / 2.0\n",
    "df_before_stop.test_misclass = (df_before_stop.test_misclass + df_before_stop.valid_misclass) / 2.0\n",
    "df_before_stop = df_before_stop.drop(['valid_misclass', 'valid_sample_misclass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_avg = dataset_averaged_frame(df_before_stop[df_before_stop.n_recordings == 500].drop('n_recordings', axis=1),\n",
    "                                'i_test_fold',['runtime',\n",
    " 'test_sample_misclass',\n",
    " 'test_misclass',\n",
    " 'train_sample_misclass',\n",
    " 'train_misclass',]).sort_values(by=('test_sample_misclass', 'mean'))\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_before_stop[(df_before_stop.batch_set_zero_test == True)\n",
    "              & (df_before_stop.batch_set_zero_val == 500) &\n",
    "              (df_before_stop.model_name == 'deep')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_before_stop[(df_before_stop.batch_set_zero_test == True)\n",
    "              & (df_before_stop.batch_set_zero_val == 500) &\n",
    "              (df_before_stop.model_name == 'shallow')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.mean(df_before_stop.test_sample_misclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.mean(df_before_stop[df_before_stop.i_test_fold == 1].test_sample_misclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_avg = dataset_averaged_frame(df_before_stop[(df_before_stop.n_recordings == 500)\n",
    "                                              & (df_before_stop.model_name == 'deep')].drop('n_recordings', axis=1),\n",
    "                                'i_test_fold',['runtime',\n",
    " 'test_sample_misclass',\n",
    " 'test_misclass',\n",
    " 'train_sample_misclass',\n",
    " 'train_misclass',]).sort_values(by=('test_sample_misclass', 'mean'))\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_avg = dataset_averaged_frame(df_before_stop[(df_before_stop.n_recordings == 500)\n",
    "                                              & (df_before_stop.model_name == 'shallow')].drop('n_recordings', axis=1),\n",
    "                                'i_test_fold',['runtime',\n",
    " 'test_sample_misclass',\n",
    " 'test_misclass',\n",
    " 'train_sample_misclass',\n",
    " 'train_misclass',]).sort_values(by=('test_sample_misclass', 'mean'))\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_avg = dataset_averaged_frame(df[df.n_recordings == 500].drop('n_recordings', axis=1),\n",
    "                                'i_test_fold',result_cols).sort_values(by=('test_sample_misclass', 'mean'))\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_avg = dataset_averaged_frame(df[df.n_recordings == 150].drop('n_recordings', axis=1),\n",
    "                                'i_test_fold',result_cols).sort_values(by=('test_sample_misclass', 'mean'))\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/preprocs-with-divide/')\n",
    "df = df[df.finished == 1]\n",
    "df = df.fillna('-')\n",
    "df = df.drop('seed', axis=1)\n",
    "df = remove_columns_with_same_value(df)\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "df = df.drop('max_min_expected', axis=1)\n",
    "print(len(df))\n",
    "df = df.rename(columns=dict(shrink_the_spikes='shrink',\n",
    "                            channel_standardize='chan_std',\n",
    "                            low_cut_hz='low_hz',\n",
    "                            max_abs_val='max_val',\n",
    "                            channel_demean='chan_mean',\n",
    "                            exp_demean='e_mean',\n",
    "                            exp_standardize='e_std',\n",
    "                            max_min_expected='max_expd',\n",
    "                            max_threshold='max_min_threshold',\n",
    "                            high_cut_hz='high_hz',\n",
    "                            moving_demean='m_mean',\n",
    "                            moving_standardize='m_std')).drop(['train_loss', 'valid_loss',\n",
    "                                                       'test_loss', 'valid_misclass',\n",
    "                                                       ], axis=1)\n",
    "df.test_misclass = df.test_misclass * 100\n",
    "df.test_sample_misclass = df.test_sample_misclass * 100\n",
    "\n",
    "df.sort_values(by='test_sample_misclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hyperoptim.results import restrict\n",
    "\n",
    "from hyperoptim.results import dataset_averaged_frame\n",
    "\n",
    "df_avg = dataset_averaged_frame(df,'i_test_fold',result_cols).sort_values(by=('test_sample_misclass', 'mean'))\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for nr in np.array(df.index):\n",
    "    epoch_df  = np.load('data/models/pytorch/auto-diag/preprocs-with-divide/{:d}/before_stop_df.pkl'.format(\n",
    "        nr))\n",
    "    display(df.ix[nr])\n",
    "\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    plt.plot(epoch_df.train_misclass * 100)\n",
    "    plt.plot(epoch_df.valid_misclass * 100)\n",
    "    plt.plot(epoch_df.test_misclass * 100)\n",
    "    plt.title(nr)\n",
    "    \n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.ix[[3,6,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.ix[[3,6,9,10,13,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "! ls data/models/pytorch/auto-diag/preprocs-more-data/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/preprocs-more-data///')\n",
    "df = df[df.finished == 1]\n",
    "df = df.fillna('-')\n",
    "df = df.drop('seed', axis=1)\n",
    "df = remove_columns_with_same_value(df)\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "df = df.drop('max_min_expected', axis=1)\n",
    "print(len(df))\n",
    "df = df.rename(columns=dict(shrink_the_spikes='shrink',\n",
    "                            channel_standardize='chan_std',\n",
    "                            low_cut_hz='low_hz',\n",
    "                            max_abs_val='max_val',\n",
    "                            channel_demean='chan_mean',\n",
    "                            exp_demean='e_mean',\n",
    "                            exp_standardize='e_std',\n",
    "                            max_min_expected='max_expd',\n",
    "                            max_threshold='max_min_threshold',\n",
    "                            high_cut_hz='high_hz',\n",
    "                            moving_demean='m_mean',\n",
    "                            moving_standardize='m_std')).drop(['train_loss', 'valid_loss',\n",
    "                                                       'test_loss', 'valid_misclass',\n",
    "                                                       ], axis=1)\n",
    "df.test_misclass = df.test_misclass * 100\n",
    "df.test_sample_misclass = df.test_sample_misclass * 100\n",
    "\n",
    "df.sort_values(by='test_misclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hyperoptim.results import restrict\n",
    "\n",
    "from hyperoptim.results import dataset_averaged_frame\n",
    "\n",
    "df_avg = dataset_averaged_frame(df,'i_test_fold',result_cols).sort_values(by=('test_sample_misclass', 'mean'))\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_avg[df_avg[('runtime', 'len')] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(df[df.model_name == 'shallow'],\n",
    "                       'i_test_fold',result_cols).sort_values(by=('test_sample_misclass', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset_averaged_frame(df[df.model_name == 'deep'],\n",
    "                       'i_test_fold',result_cols).sort_values(by=('test_sample_misclass', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_no_std = restrict(df, e_std=False, m_std=False, chan_std=False)\n",
    "df_std = df[(df.e_std == True) | (df.m_std == True) |\n",
    "            (df.chan_std == True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_std.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_no_std.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_no_mean = restrict(df, e_mean=False, m_mean=False, chan_mean=False)\n",
    "df_mean = df[(df.e_mean == True) | (df.m_mean == True) |\n",
    "            (df.chan_mean == True)]\n",
    "\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_mean.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_no_mean.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_no_high = restrict(df, high_hz='-')\n",
    "df_high = df[(df.high_hz == 45)]\n",
    "\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_high.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_no_high.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_no = restrict(df, shrink=False)\n",
    "df_yes = df[(df.shrink == True)]\n",
    "\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_yes.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_no.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_no = restrict(df, max_min_threshold='-')\n",
    "df_yes = df[(df.max_min_threshold == 600)]\n",
    "\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_yes.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_no.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_no = restrict(df, max_val='-')\n",
    "df_yes = df[(df.max_val == 800)]\n",
    "\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_yes.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_no.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_shrink = df[(df.shrink == True) & (df.max_val == '-')]\n",
    "df_max_min = df[(df.max_min_threshold == 600) & (df.max_val == '-')]\n",
    "df_max_abs = df[(df.max_min_threshold == '-')& (df.max_val == 800) & (df.shrink == False)]\n",
    "\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_shrink.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_max_min.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_max_abs.test_sample_misclass)\n",
    "plt.plot(2 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_shrink = df_mean[(df_mean.shrink == True) & (df_mean.max_val == '-')]\n",
    "df_max_min = df_mean[(df_mean.max_min_threshold == 600) & (df_mean.max_val == '-')]\n",
    "df_max_abs = df_mean[(df_mean.max_min_threshold == '-')& (df_mean.max_val == 800) & (df_mean.shrink == False)]\n",
    "\n",
    "rng = RandomState(39847348)\n",
    "accs =  (100 - df_shrink.test_sample_misclass)\n",
    "plt.plot(rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_max_min.test_sample_misclass)\n",
    "plt.plot(1 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "accs =  (100 - df_max_abs.test_sample_misclass)\n",
    "plt.plot(2 + rng.randn(len(accs)) * 0.1, accs, ls='', marker='o', alpha=0.5)\n",
    "plt.xlim(-0.5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result_cols = ['runtime', 'test_sample_misclass', 'train_misclass', 'valid_sample_misclass', 'test_misclass', \n",
    "               'train_sample_misclass']\n",
    "\n",
    "pairwise_compare_frame(df,result_cols=result_cols,compare_col='test_misclass', with_p_vals=True).sort_values(by='p_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pairwise_compare_frame(df,result_cols=result_cols,compare_col='test_sample_misclass', with_p_vals=True).sort_values(by='p_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result_cols = ['runtime', 'test_sample_misclass', 'train_misclass', 'valid_sample_misclass', 'test_misclass', \n",
    "               'train_sample_misclass']\n",
    "\n",
    "pairwise_compare_frame(df,result_cols=result_cols,compare_col='runtime', with_p_vals=True).sort_values(by='p_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(df[df.test_sample_misclass < 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pairwise_compare_frame(df[df.test_sample_misclass < 18],\n",
    "                       result_cols=result_cols,compare_col='test_sample_misclass', with_p_vals=True).sort_values(by='p_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/preprocs//')\n",
    "df = df[df.finished == 1]\n",
    "df = df.fillna('-')\n",
    "df = df.drop('seed', axis=1)\n",
    "df = remove_columns_with_same_value(df)\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "df = df.drop('max_min_expected', axis=1)\n",
    "print(len(df))\n",
    "df = df.rename(columns=dict(shrink_the_spikes='shrink',\n",
    "                      channel_standardize='chan_std',\n",
    "                      low_cut_hz='low_hz',\n",
    "                      max_abs_val='max_val',\n",
    "                      channel_demean='chan_mean',\n",
    "                      exp_demean='e_mean',\n",
    "                      exp_standardize='e_std',\n",
    "                      max_threshold='max_min_threshold',\n",
    "                      high_cut_hz='high_hz',\n",
    "                      moving_demean='m_mean',\n",
    "                      moving_standardize='m_std')).drop(['train_loss', 'valid_loss',\n",
    "                                                   'test_loss', 'valid_misclass',\n",
    "                                                   ], axis=1)\n",
    "df.test_misclass = df.test_misclass * 100\n",
    "df.test_sample_misclass = df.test_sample_misclass * 100\n",
    "\n",
    "df.sort_values(by='test_misclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='test_sample_misclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_cols = ['runtime', 'test_sample_misclass', 'train_misclass', 'valid_sample_misclass', 'test_misclass', \n",
    "               'train_sample_misclass']\n",
    "\n",
    "pairwise_compare_frame(df,result_cols=result_cols,compare_col='test_misclass', with_p_vals=True).sort_values(by='p_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pairwise_compare_frame(df,result_cols=result_cols,compare_col='test_sample_misclass', with_p_vals=True).sort_values(by='p_val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = load_data_frame('data/models/pytorch/auto-diag/first-try/')\n",
    "df = df[df.finished == 1]\n",
    "df = df.fillna('-')\n",
    "df = df[df.max_epochs == 35]\n",
    "df = remove_columns_with_same_value(df)\n",
    "df.runtime = pd.to_timedelta(np.round(df.runtime), unit='s')\n",
    "\n",
    "#df = df.sort_values(by='alpha')\n",
    "#df = df[df.batch_norm == True]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
